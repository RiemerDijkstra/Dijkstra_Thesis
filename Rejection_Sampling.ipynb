{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19516,
     "status": "ok",
     "timestamp": 1624584326039,
     "user": {
      "displayName": "Riemer Dijkstra",
      "photoUrl": "",
      "userId": "01054650060903474658"
     },
     "user_tz": -120
    },
    "id": "FCH6ag6jtqEa",
    "outputId": "8bbd2606-51ed-4852-b1e9-02e4190f743c"
   },
   "outputs": [],
   "source": [
    "!python3 -m pip install transformers\n",
    "!python3 -m pip install seaborn\n",
    "!python3 -m pip install statsmodels\n",
    "!python3 -m pip install tensorflow==1.4.1\n",
    "!python3 -m pip install torch\n",
    "!python3 -m pip install nltk\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 947,
     "status": "ok",
     "timestamp": 1624584326968,
     "user": {
      "displayName": "Riemer Dijkstra",
      "photoUrl": "",
      "userId": "01054650060903474658"
     },
     "user_tz": -120
    },
    "id": "LlDiu4ON_IvS",
    "outputId": "166b663a-e8ec-4368-91e5-15259cb333cd"
   },
   "outputs": [],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pVNcHh6LmEGP"
   },
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8199,
     "status": "ok",
     "timestamp": 1624584483813,
     "user": {
      "displayName": "Riemer Dijkstra",
      "photoUrl": "",
      "userId": "01054650060903474658"
     },
     "user_tz": -120
    },
    "id": "hQbcvYP7mGlG",
    "outputId": "97211944-bc3b-40ef-d235-b8450de412a1"
   },
   "outputs": [],
   "source": [
    "# Riemer\n",
    "from mle import Mandelbrot\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# Rachel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.optimize import minimize\n",
    "import math\n",
    "import json\n",
    "from nltk import tokenize\n",
    "import collections\n",
    "import re\n",
    "import sys\n",
    "import itertools\n",
    "import time\n",
    "import nltk\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.base.model import GenericLikelihoodModel,\\\n",
    "        GenericLikelihoodModelResults\n",
    "\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "\n",
    "from scipy.special import zeta\n",
    "from scipy.stats import binom\n",
    "\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "lg = np.log10\n",
    "\n",
    "from scipy.stats import chisquare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "58iA9UacFUyY"
   },
   "source": [
    "# Model Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269,
     "referenced_widgets": [
      "8ce96608d3fe4dcca5f47ee9da80cae5",
      "c910715cd8854f81999fbba19a474a00",
      "e7e64c3e2c974e5185a2c97e49d4391c",
      "ddb279d017934b5d899beb6ba9b19b35",
      "62399ecdd8ef45ba9e00a8c21066b366",
      "e1009d8b9f694b0bba841632ecceb970",
      "ce65de69034346b088ef352c887df60e",
      "4b71f1fec57345eabe06d30474e4a92e",
      "e1be793186634798b916839edbe61e6f",
      "d71759655da840b592ea3f1584b97dc8",
      "17a3b5fa575f438b9575182f0479fe4d",
      "de29825227524215b9f74d29a293d05c",
      "62aed2da6d9144aba3dc6ff0865a9b4f",
      "7f5df7cb170d49bb8e839b07f5ccf574",
      "0048304c20d64cbe8d4c6a4713dded11",
      "894105888abe40408e128ffe231edd97",
      "7442df3d662d4fa8bf66fe80e4807502",
      "420e2c3ef8cc456dab537fb2827cffe1",
      "b9c06a0281274909a06a77302ea43b96",
      "9518fb90c2674070b00b5b85f1945cb4",
      "6d9760a4922d4406ba5175d2e135c6e4",
      "3a76b63949014a4496553ecaf14ef359",
      "08b15cd436644910980e60f9d876b934",
      "21264b9ba0b84c11ab38ba2850ea56d1",
      "a059d4ee61964a3d8af5512a0c1bcf5e",
      "72332c302797499284bf5a262c7a11a9",
      "c153f5a9adbb4b35918817a42b791025",
      "abaeb1c0a87541fab1ff33428e4d4631",
      "3666e841186942f786735bb4855c62ea",
      "e4d8750fa76148088ccf0b6476a5ecef",
      "2e8829f9d9b64bbbb5f87c646eea41d0",
      "95464dd3ba284517a22da28b78fea530",
      "f11696934ca84ae1b861d75d317a90f1",
      "e0dc6290c0b145cf8d7a3a98e7a8b04c",
      "44ff5e992b924286b45dd03fbd44747c",
      "257e52d3ac734ad38c131618b2eb701f",
      "39650bc1c98a4a9da39fa13cfea6714d",
      "c2028efcaac14b5ab95ee2e2021ded71",
      "a58e87e0e3cb4527bdd2c1c0419b6d69",
      "8510afa35f204020832c07a37356e034"
     ]
    },
    "executionInfo": {
     "elapsed": 28233,
     "status": "ok",
     "timestamp": 1624584512040,
     "user": {
      "displayName": "Riemer Dijkstra",
      "photoUrl": "",
      "userId": "01054650060903474658"
     },
     "user_tz": -120
    },
    "id": "zkd8IyvvFWdQ",
    "outputId": "4693779f-a099-44e7-aef8-85cbdd4b907b"
   },
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-small\")\n",
    "\n",
    "# add the EOS token as PAD token to avoid warnings\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2-small\", pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VbaPXSMIs5qG"
   },
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4137,
     "status": "ok",
     "timestamp": 1624584516170,
     "user": {
      "displayName": "Riemer Dijkstra",
      "photoUrl": "",
      "userId": "01054650060903474658"
     },
     "user_tz": -120
    },
    "id": "tB0J-77qp8Hl"
   },
   "outputs": [],
   "source": [
    "gpt_set = pickle.load(open(\"datasets/gpt_set.p\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3793,
     "status": "ok",
     "timestamp": 1624584519956,
     "user": {
      "displayName": "Riemer Dijkstra",
      "photoUrl": "",
      "userId": "01054650060903474658"
     },
     "user_tz": -120
    },
    "id": "3_GayVDes7-o"
   },
   "outputs": [],
   "source": [
    "human_set = pickle.load(open(\"datasets/human_set.p\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5671,
     "status": "ok",
     "timestamp": 1624584525625,
     "user": {
      "displayName": "Riemer Dijkstra",
      "photoUrl": "",
      "userId": "01054650060903474658"
     },
     "user_tz": -120
    },
    "id": "E0XsBj5pwRLV"
   },
   "outputs": [],
   "source": [
    "Wiki = open(\"datasets/Wiki.txt\", \"r\").read()\n",
    "\n",
    "wiki_set = Wiki.split('</doc>')[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1721,
     "status": "ok",
     "timestamp": 1624584527340,
     "user": {
      "displayName": "Riemer Dijkstra",
      "photoUrl": "",
      "userId": "01054650060903474658"
     },
     "user_tz": -120
    },
    "id": "UeW8c1OLxiD_"
   },
   "outputs": [],
   "source": [
    "GPT = open(\"datasets/GPT-2.txt\", \"r\").read()\n",
    "\n",
    "GPT_set = GPT.split('</doc>')[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yWBVrw79-ZUW"
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 551,
     "status": "ok",
     "timestamp": 1624584527883,
     "user": {
      "displayName": "Riemer Dijkstra",
      "photoUrl": "",
      "userId": "01054650060903474658"
     },
     "user_tz": -120
    },
    "id": "R_qW0eMF-dq1"
   },
   "outputs": [],
   "source": [
    "# Pre-processing without part of speech tags\n",
    "def remove_punctuation(text):\n",
    "    text = text.lower()\n",
    "    chars_to_remove = \"[\\n]!\\\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\n",
    "    tr = str.maketrans(\" \", \" \", chars_to_remove)\n",
    "    return text.translate(tr)\n",
    "\n",
    "\n",
    "def preprocess(corpus, sent = True):\n",
    "    if sent:\n",
    "        corpus = tokenize.sent_tokenize(corpus)\n",
    "        corpus = [remove_punctuation(sent).split() for sent in corpus]\n",
    "    else:\n",
    "        corpus = remove_punctuation(corpus).split()\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 37,
     "status": "ok",
     "timestamp": 1624584527884,
     "user": {
      "displayName": "Riemer Dijkstra",
      "photoUrl": "",
      "userId": "01054650060903474658"
     },
     "user_tz": -120
    },
    "id": "LTmfbRfc-iX_"
   },
   "outputs": [],
   "source": [
    "# Pre-processing with part of speech tags\n",
    "def part_of_speech(corpus):\n",
    "    corpus = tokenize.sent_tokenize(corpus)\n",
    "    chars_to_remove = \"[\\n]\"\n",
    "    tr = str.maketrans(\" \", \" \", chars_to_remove)\n",
    "    chars_to_remove2 = \"[\\n]!\\\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\n",
    "    new_corp = []\n",
    "    test = []\n",
    "\n",
    "    for sent in corpus:\n",
    "        sent = sent.translate(tr)\n",
    "        words_sent = tokenize.word_tokenize(sent)\n",
    "        sent_pos = nltk.pos_tag(words_sent)\n",
    "        new_sent = []\n",
    "        for (word, pos) in sent_pos:\n",
    "            tr2 = str.maketrans(\"\", \"\", chars_to_remove2)\n",
    "            word = word.translate(tr2)\n",
    "            if word:\n",
    "                new_sent.append((word.lower(), pos))\n",
    "        new_corp.append(new_sent)\n",
    "    return new_corp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1624584527884,
     "user": {
      "displayName": "Riemer Dijkstra",
      "photoUrl": "",
      "userId": "01054650060903474658"
     },
     "user_tz": -120
    },
    "id": "Rn7xJ5xM-k8t"
   },
   "outputs": [],
   "source": [
    "# Total preprocessing function for a corpus. Input can be one string (corpus),\n",
    "# for which you put multi = False, or a list of several strings (corpora) that \n",
    "# you want to turn into one big corpus, for which you put multi = True.\n",
    "# For PoS tags, put pos = True.\n",
    "def make_file(corp, multi = True, sent = True, pos = False):\n",
    "    if multi:\n",
    "        corpus = ''\n",
    "        for subcorp in corp:\n",
    "            corpus += subcorp\n",
    "    else:\n",
    "        corpus = corp\n",
    "        \n",
    "    if pos:\n",
    "        corpus = part_of_speech(corpus)\n",
    "    \n",
    "    else:\n",
    "        corpus = preprocess(corpus, sent = sent)\n",
    "    \n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cfHwqJY6uANx"
   },
   "source": [
    "# Rachel Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mea2NvkguNlk"
   },
   "source": [
    "## Subsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1624584527885,
     "user": {
      "displayName": "Riemer Dijkstra",
      "photoUrl": "",
      "userId": "01054650060903474658"
     },
     "user_tz": -120
    },
    "id": "UaXExdDDuRIp"
   },
   "outputs": [],
   "source": [
    "# Returns 2 lists of corpora, one from which the ranks will be calculated\n",
    "# and one from which the frequencies will be calculated. Each corpus consists of\n",
    "# a list of tokenized sentences.\n",
    "# Input: corpus that is to be subsampled. Should be a list of tokenized sentences.\n",
    "# k is the amount of tokens that each sampled corpus should contain,\n",
    "# m is the amount of subcorpera you want for both the ranks and frequencies.\n",
    "# Max: I would read Valentin's thesis for an explanation on subsampling\n",
    "def subsampling(corpus, k = 1000000, m = 10, sent = True):\n",
    "    n = len(corpus)\n",
    "    \n",
    "    sen_len = {}\n",
    "\n",
    "    \n",
    "    rank_corpera = []\n",
    "    freq_corpera = []\n",
    "\n",
    "    if sent:\n",
    "        for i in range(m):\n",
    "            used_rank = set()\n",
    "            used_freq = set()\n",
    "            rank_count = 0\n",
    "            freq_count = 0\n",
    "            rank_samples = []\n",
    "            freq_samples = []\n",
    "\n",
    "            while rank_count < k:\n",
    "                index = np.random.randint(n)\n",
    "                if index in used_rank:\n",
    "                    continue\n",
    "\n",
    "                rank_sample = corpus[index]\n",
    "                len_sample = len(rank_sample)\n",
    "\n",
    "                if len_sample == 0:\n",
    "                    continue\n",
    "\n",
    "                if rank_count > k:\n",
    "                    max_len = len_sample - (rank_count - k)\n",
    "                    rank_sample = rank_sample[:max_len]\n",
    "                    \n",
    "                rank_samples += rank_sample\n",
    "                rank_count += len_sample\n",
    "\n",
    "\n",
    "                used_rank.add(index)\n",
    "\n",
    "            while freq_count < k:\n",
    "                index = np.random.randint(n)\n",
    "                if index in used_freq:\n",
    "                    continue\n",
    "                freq_sample = corpus[index]\n",
    "                len_sample = len(freq_sample)\n",
    "\n",
    "                if len_sample == 0:\n",
    "                    continue\n",
    "                    \n",
    "                if freq_count > k:\n",
    "                    max_len = len_sample - (freq_count - k)\n",
    "                    freq_sample = freq_sample[:max_len]\n",
    "\n",
    "                freq_samples += freq_sample\n",
    "                freq_count += len_sample\n",
    "\n",
    "                if len_sample not in sen_len and len_sample < 200:\n",
    "                    sen_len[len_sample] = 1\n",
    "                elif len_sample < 200:\n",
    "                    sen_len[len_sample] += 1\n",
    "\n",
    "                used_freq.add(index)\n",
    "\n",
    "            rank_corpera.append(rank_samples)\n",
    "            freq_corpera.append(freq_samples)\n",
    "#                 rank_corpera.append([item for sublist in rank_samples for item in sublist])\n",
    "#                 freq_corpera.append([item for sublist in freq_samples for item in sublist])\n",
    "\n",
    "\n",
    "    else:\n",
    "        for i in range(m):\n",
    "            rank_samples = random.sample(corpus, k)\n",
    "            freq_samples = random.sample(corpus, k)\n",
    "            rank_corpera.append(rank_samples)\n",
    "            freq_corpera.append(freq_samples)\n",
    "    \n",
    "#     return rank_corpera, freq_corpera, sen_len\n",
    "    return rank_corpera, freq_corpera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1624584527886,
     "user": {
      "displayName": "Riemer Dijkstra",
      "photoUrl": "",
      "userId": "01054650060903474658"
     },
     "user_tz": -120
    },
    "id": "k1JoEy9MuR4p"
   },
   "outputs": [],
   "source": [
    "# Returns a dataframe of word frequencies for list of corpora,\n",
    "# with each column corresponding to a different corpus.\n",
    "# Input: list of corpora. Each corpus consists of a list of tokenized sentences.\n",
    "def calculate_freqs(freq_sents, norm=True, text=None):\n",
    "    freq_dict = {}\n",
    "    norm_dict = {}\n",
    "    for i, corpus in enumerate(freq_sents):\n",
    "        freq_dict['{} c_frequency {}'.format(text,i)] = collections.Counter(corpus)\n",
    "        if norm:\n",
    "            len_corp = len(corpus)\n",
    "            norm_dict['{} c_frequency {}'.format(text, i)] = {k: v / len_corp for k, v in freq_dict['{} c_frequency {}'.format(text,i)].items()}\n",
    "    \n",
    "    if norm:\n",
    "        freqs_df = pd.DataFrame(norm_dict)\n",
    "    else:\n",
    "        freqs_df = pd.DataFrame(freq_dict)\n",
    "    freqs_df = freqs_df.fillna(0)\n",
    "    \n",
    "    \n",
    "    return freqs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1624584527886,
     "user": {
      "displayName": "Riemer Dijkstra",
      "photoUrl": "",
      "userId": "01054650060903474658"
     },
     "user_tz": -120
    },
    "id": "s2uwYg8auWiR"
   },
   "outputs": [],
   "source": [
    "# Returns a dataframe with the mean frequency of each word across different corpora.\n",
    "# Input: frequency dataframe\n",
    "def mean_freqs(freqs_df):\n",
    "    return(freqs_df.mean(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1624584527887,
     "user": {
      "displayName": "Riemer Dijkstra",
      "photoUrl": "",
      "userId": "01054650060903474658"
     },
     "user_tz": -120
    },
    "id": "7LeySfvtuXzC"
   },
   "outputs": [],
   "source": [
    "# Returns a dataframe of word ranks for list of corpora,\n",
    "# with each column corresponding to a different corpus.\n",
    "# Input: list of corpora. Each corpus consists of a list of tokenized sentences.\n",
    "def calculate_ranks(rank_sents, norm=False, text=None):\n",
    "    ranks_dicts = {}\n",
    "    for i, corpus in enumerate(rank_sents):\n",
    "        freqs = collections.Counter(corpus)\n",
    "        if norm:\n",
    "            len_corp = len(corpus)\n",
    "            for key in freqs:\n",
    "                freqs[key] /= len_corp\n",
    "        ranks_dicts['{} c_rank {}'.format(text, i)] = {w: r for r, (w, c) in enumerate(freqs.most_common(), 1)}\n",
    "    \n",
    "    ranks_df = pd.DataFrame(ranks_dicts)\n",
    "    for column in ranks_df:\n",
    "        min_rank = int(np.ceil(ranks_df[column].max() + 1))\n",
    "        nan_rows = ranks_df[ranks_df[column].isnull()]\n",
    "        num_nans = len(nan_rows)\n",
    "        nan_ranks = list(range(min_rank, min_rank+num_nans))\n",
    "        random.shuffle(nan_ranks)\n",
    "        ranks_df.loc[ranks_df[column].isnull(), column] = nan_ranks\n",
    "\n",
    "    return ranks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1624584527888,
     "user": {
      "displayName": "Riemer Dijkstra",
      "photoUrl": "",
      "userId": "01054650060903474658"
     },
     "user_tz": -120
    },
    "id": "45BNDOlkuY8p"
   },
   "outputs": [],
   "source": [
    "# Returns a dataframe with the mean rank of each word across different corpora.\n",
    "# Input: rank dataframe\n",
    "def mean_ranks(ranks_df):\n",
    "    return ranks_df.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1624584527888,
     "user": {
      "displayName": "Riemer Dijkstra",
      "photoUrl": "",
      "userId": "01054650060903474658"
     },
     "user_tz": -120
    },
    "id": "xWevBUASuaUB"
   },
   "outputs": [],
   "source": [
    "# Creates combined dataframe of ranks and frequencies\n",
    "# Input: 2 lists (freq_sents and rank_sents) of corpora. Each corpus\n",
    "# consists of a list of tokenized sentences. These lists are to be obtained form\n",
    "# subsampling.\n",
    "def ranks_freqs(freq_sents, rank_sents, text=None, norm=False):\n",
    "    freqs_df = calculate_freqs(freq_sents, text=text, norm=norm)\n",
    "    freqs_df['Frequency'] = mean_freqs(freqs_df)\n",
    "    ranks_df = calculate_ranks(rank_sents, text=text, norm=norm)\n",
    "    ranks_df['Rank'] = mean_ranks(ranks_df)\n",
    "    \n",
    "    # Put mean ranks and freqs together and remove all words that\n",
    "    # do not have both a rank and frequency (which happens when a word)\n",
    "    # is only present in freq_sents and not in rank_sents or vice versa\n",
    "    ranks_freqs_df = pd.concat([ranks_df, freqs_df], axis = 1)\n",
    "    ranks_freqs_df = ranks_freqs_df.dropna()\n",
    "#     ranks_freqs_df = ranks_freqs_df.loc[ranks_freqs_df['Frequency'] >=1]\n",
    "    return ranks_freqs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wbQN5bDgu2C7"
   },
   "source": [
    "## Zipf's law (param estimation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1624584527889,
     "user": {
      "displayName": "Riemer Dijkstra",
      "photoUrl": "",
      "userId": "01054650060903474658"
     },
     "user_tz": -120
    },
    "id": "6O9ZywsJuc1O"
   },
   "outputs": [],
   "source": [
    "# Returns a dataframe containing the mean frequencies and ranks, as well as \n",
    "# the estimated frequencies from Zipf's law and the error between the (log) mean\n",
    "# frequencies and (log) estimated frequencies.\n",
    "def zipfs_law(df, print_stats = True):\n",
    "    mandelbrot = Mandelbrot(df['Frequency'], df['Rank'])\n",
    "    mandelbrot_fit = mandelbrot.fit(start_params=np.asarray([1.0, 1.0]), # [1.0, 1.0]\n",
    "                                method=\"powell\", full_output=True, disp=0)\n",
    "    mandelbrot.register_fit(mandelbrot_fit)\n",
    "    if print_stats:\n",
    "        mandelbrot.print_result()\n",
    "    \n",
    "    model_params = mandelbrot.optim_params\n",
    "    alpha, beta =  mandelbrot.optim_params\n",
    "    preds = mandelbrot.predict(model_params, df['Rank'])\n",
    "\n",
    "    df['Estimated frequency'] = preds\n",
    "    return df, [alpha, beta]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FxVBPPO0u6YC"
   },
   "source": [
    "## Plot Zipf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1624584527889,
     "user": {
      "displayName": "Riemer Dijkstra",
      "photoUrl": "",
      "userId": "01054650060903474658"
     },
     "user_tz": -120
    },
    "id": "O9BjmJqqukAc"
   },
   "outputs": [],
   "source": [
    "def plot_zipf(ranks_freqs_df):\n",
    "    ranks_freqs_df = ranks_freqs_df.sort_values(by=['Rank'])\n",
    "    zipf_df, params = zipfs_law(ranks_freqs_df)\n",
    "#     ranks_freqs_df = ranks_freqs_df.loc[ranks_freqs_df['Frequency'] >=1]\n",
    "#     hexbin_plot(ranks_freqs_df['Rank'], ranks_freqs_df['Frequency'], est = ranks_freqs_df['Estimated frequency'])\n",
    "#     plt.show()\n",
    "#     hexbin_error(zipf_df['Rank (log)'], zipf_df['Error'])\n",
    "#     plt.show()\n",
    "    \n",
    "    return zipf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1624584527889,
     "user": {
      "displayName": "Riemer Dijkstra",
      "photoUrl": "",
      "userId": "01054650060903474658"
     },
     "user_tz": -120
    },
    "id": "U8JrCTSFulhD"
   },
   "outputs": [],
   "source": [
    "# Divides a big corpus into \"n\" subcorpera and calculates the frequencies for each\n",
    "# subcorpus. Returns a dataframe containing the frequencies by word and by rank.\n",
    "def sample_corpora(corpus, text, n=10, norm=True, subclasses=False, pos=True,size=10):\n",
    "    corpus = [item for sublist in corpus for item in sublist]\n",
    "    rank_corp, freq_corp = subsampling(corpus, k=size*100, m=n)\n",
    "\n",
    "    if len(rank_corp[0]) == 0:\n",
    "      print(corpus)\n",
    "\n",
    "    by_rank = pd.DataFrame()\n",
    "    by_word = pd.DataFrame()\n",
    "\n",
    "    ranks_freqs_df = ranks_freqs(rank_corp, freq_corp, text=text, norm=norm)\n",
    "    ranks_freqs_df, params = zipfs_law(ranks_freqs_df, print_stats=False)\n",
    "    \n",
    "    return  params\n",
    "#     return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1624584527890,
     "user": {
      "displayName": "Riemer Dijkstra",
      "photoUrl": "",
      "userId": "01054650060903474658"
     },
     "user_tz": -120
    },
    "id": "oXGVvhe1unRr"
   },
   "outputs": [],
   "source": [
    "# Takes 2 corpora and aligns their frequency values by specific words and ranks \n",
    "# so that the Mann-Whitney test can be applied to the frequencies of every word\n",
    "# or rank.\n",
    "def mann_whitney_df(corpus, human, gpt, size, n=10, t=0, norm=True, subclasses=False):\n",
    "    params_c = sample_corpora(corpus, text=\"C1\", n=n, norm=norm, subclasses=subclasses,size=size)\n",
    "    params_h = sample_corpora(human, text=\"C2\", n=n, norm=norm, subclasses=subclasses,size=size)\n",
    "    params_g = sample_corpora(gpt, text=\"C2\", n=n, norm=norm, subclasses=subclasses,size=size)\n",
    "    \n",
    "    \n",
    "    dist_h = np.linalg.norm(np.array(params_c)-np.array(params_h))\n",
    "    dist_g = np.linalg.norm(np.array(params_c)-np.array(params_g))\n",
    "    \n",
    "    return [dist_h, dist_g] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1624584527890,
     "user": {
      "displayName": "Riemer Dijkstra",
      "photoUrl": "",
      "userId": "01054650060903474658"
     },
     "user_tz": -120
    },
    "id": "R1OPb9Stuol2"
   },
   "outputs": [],
   "source": [
    "# Takes 2 corpora, and applies the Mann-Whitney procedure to \"times\" subparts\n",
    "# of both corpora. \n",
    "# Returns dataframes containing distributions of the total percentages as well \n",
    "# as per-rank percentages of rejected H0 ranks and words.\n",
    "def stats_dist2(corpus, human, gpt, times=10, n=10, t=0, norm=True, subclasses=False, pos=False):\n",
    "    len_corp = int(len(human)/10)\n",
    "    dists = []\n",
    "    \n",
    "    for i in range(times):\n",
    "        corpus_samp = corpus\n",
    "        human_samp = human[i*len_corp:(i+1)*len_corp]\n",
    "        gpt_samp = gpt[i*len_corp:(i+1)*len_corp]\n",
    "        dist = mann_whitney_df(corpus, human_samp, gpt_samp,size=len_corp, n=n, t=t, norm=norm, subclasses=subclasses)\n",
    "        dists.append(dist)\n",
    "   \n",
    "    return dists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q9KntMeZwDDt"
   },
   "source": [
    "# Test (Zipf params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 614,
     "status": "ok",
     "timestamp": 1624591003446,
     "user": {
      "displayName": "Riemer Dijkstra",
      "photoUrl": "",
      "userId": "01054650060903474658"
     },
     "user_tz": -120
    },
    "id": "LwkuIYGZwE99"
   },
   "outputs": [],
   "source": [
    "def test(corpus, size, rep = 1, times = 10, n=10, sub=True):\n",
    "  \n",
    "    dist_human = 0\n",
    "    dist_machine = 0\n",
    "\n",
    "    corpus = corpus\n",
    "    human = human_set\n",
    "    random.shuffle(human)\n",
    "    gpt = gpt_set\n",
    "    random.shuffle(gpt)\n",
    "    dists = stats_dist2(corpus, human[0:size*times], gpt[0:size*times], times=times, n=n)\n",
    "\n",
    "    if dists[0] < dists[1]:\n",
    "      print(\"corpus is human\")\n",
    "      return True\n",
    "    else:\n",
    "      print(\"corpus is gpt-2\")\n",
    "      return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2763,
     "status": "ok",
     "timestamp": 1624584530632,
     "user": {
      "displayName": "Riemer Dijkstra",
      "photoUrl": "",
      "userId": "01054650060903474658"
     },
     "user_tz": -120
    },
    "id": "ATtmU3aPwF98",
    "outputId": "4a652f27-6df5-4d2e-fa3e-b4ac93e026be"
   },
   "outputs": [],
   "source": [
    "test(human_set[0:10], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3532,
     "status": "ok",
     "timestamp": 1624554847287,
     "user": {
      "displayName": "Riemer Dijkstra",
      "photoUrl": "",
      "userId": "01054650060903474658"
     },
     "user_tz": -120
    },
    "id": "GhoyMxKvAmMv",
    "outputId": "df8eab26-d64b-4afc-ee51-9b191848a659"
   },
   "outputs": [],
   "source": [
    "test(wiki_set[0:10], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4183,
     "status": "ok",
     "timestamp": 1624554906425,
     "user": {
      "displayName": "Riemer Dijkstra",
      "photoUrl": "",
      "userId": "01054650060903474658"
     },
     "user_tz": -120
    },
    "id": "Ztmbn1QdAmEs",
    "outputId": "0b6131c9-1dd6-4e8f-de85-351e505760ca"
   },
   "outputs": [],
   "source": [
    "corpus = make_file(wiki_set[0:10], multi=True, pos=True)\n",
    "\n",
    "test(corpus, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qk2xjf5OB_7U"
   },
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HoL0YfkhCHuE"
   },
   "source": [
    "## Prompt maker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 424,
     "status": "ok",
     "timestamp": 1624584650037,
     "user": {
      "displayName": "Riemer Dijkstra",
      "photoUrl": "",
      "userId": "01054650060903474658"
     },
     "user_tz": -120
    },
    "id": "cBS566i2CBbb"
   },
   "outputs": [],
   "source": [
    "def make_prompt(article, begin=True):\n",
    "  \n",
    "    article_sents = nltk.tokenize.sent_tokenize(article)\n",
    "    sent_num = len(article_sents)\n",
    "\n",
    "    if begin is True:\n",
    "      if sent_num >= 3:\n",
    "        return ' '.join(article_sents[:3])\n",
    "      if sent_num >= 2:\n",
    "        return ' '.join(article_sents[:2])\n",
    "      else:\n",
    "        return article_sents[0]\n",
    "    elif sent_num >= 3:\n",
    "      return ' '.join(article_sents[-3:])\n",
    "    elif sent_num >= 2:\n",
    "      return ' '.join(article_sents[-2:])\n",
    "    else:\n",
    "      return article_sents[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ixd20_ZCJ4r"
   },
   "source": [
    "## Section Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 508,
     "status": "ok",
     "timestamp": 1624591541159,
     "user": {
      "displayName": "Riemer Dijkstra",
      "photoUrl": "",
      "userId": "01054650060903474658"
     },
     "user_tz": -120
    },
    "id": "NKPZyJjrCEXz"
   },
   "outputs": [],
   "source": [
    "def generate_section(section, min_tokens, k, p, t, rep_pen, n_gram, seed):\n",
    "    \n",
    "    prompt = make_prompt(section, begin=True)\n",
    "    prompt_len = len(prompt.split())\n",
    "        \n",
    "    in_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
    "    in_ids = in_ids.to(\"cuda\")\n",
    "    \n",
    "    curr_id_len = len(in_ids[0])\n",
    "    max_len = min_len = curr_id_len+128\n",
    "\n",
    "    out = []\n",
    "    \n",
    "    while len(out) <= min_tokens:\n",
    "        \n",
    "        torch.manual_seed(seed)\n",
    "            \n",
    "        out_ids = model.generate(\n",
    "            in_ids,\n",
    "            do_sample=True,\n",
    "            max_length=max_len,\n",
    "            min_length=min_len,\n",
    "            top_k=k,\n",
    "            top_p=p,\n",
    "            temperature=t,\n",
    "            repetition_penalty=rep_pen,\n",
    "            no_repeat_ngram_size=n_gram\n",
    "        )\n",
    "        \n",
    "        output = tokenizer.decode(out_ids[0], skip_special_tokens=True).split()      \n",
    "        output_no_prompt = output[prompt_len:]\n",
    "        out.extend(output_no_prompt)\n",
    "        \n",
    "        output_full = \" \".join(output)\n",
    "        prompt = make_prompt(output_full, begin=False)\n",
    "        prompt_len = len(prompt.split())\n",
    "                \n",
    "        in_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
    "        in_ids = in_ids.to(\"cuda\")\n",
    "        \n",
    "        # Error control\n",
    "        if len(in_ids[0]) == curr_id_len+128:\n",
    "            \n",
    "            print('in_id error')\n",
    "            return False\n",
    "            \n",
    "            out_sents = nltk.tokenize.sent_tokenize(\" \".join(out))\n",
    "            if len(out_sents) > 1:\n",
    "                new_sents = \" \".join(out_sents[:-2])\n",
    "            else:\n",
    "                new_sents = \" \".join(out_sents)\n",
    "\n",
    "            out = new_sents.split()\n",
    "            \n",
    "            prompt = make_prompt(new_sents, begin=False)\n",
    "            prompt_len = len(prompt.split())\n",
    "            \n",
    "            in_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
    "            in_ids = in_ids.to(\"cuda\")\n",
    "            \n",
    "        curr_id_len = len(in_ids[0])\n",
    "        max_len = min_len = curr_id_len+128\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1624591542654,
     "user": {
      "displayName": "Riemer Dijkstra",
      "photoUrl": "",
      "userId": "01054650060903474658"
     },
     "user_tz": -120
    },
    "id": "G6k0NjL4I0Jt"
   },
   "outputs": [],
   "source": [
    "def generate(txt, k, p, t, rep_pen, n_gram, seed):\n",
    "    \n",
    "    new_tokens = []\n",
    "\n",
    "    sections = txt.split('\\n\\n')\n",
    "    for section in sections:\n",
    "        sec_len = len(section.split())\n",
    "        if sec_len > 10:\n",
    "            \n",
    "            curr_tokens = generate_section(\n",
    "                section, \n",
    "                min_tokens=sec_len, \n",
    "                k=k, \n",
    "                p=p, \n",
    "                t=t, \n",
    "                rep_pen=rep_pen, \n",
    "                n_gram=n_gram,\n",
    "                seed=seed\n",
    "            )\n",
    "            \n",
    "            if curr_tokens is False:\n",
    "                return False\n",
    "            \n",
    "            new_tokens.extend(curr_tokens[:sec_len] + [\"\\n\\n\"])\n",
    "\n",
    "    new_txt = \" \".join(new_tokens)\n",
    "    return new_txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ysbq9DgCBziv"
   },
   "source": [
    "# Rejection Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9sfDMCE76kNK"
   },
   "source": [
    "### Zipf parameters Human set (1.000 token set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 445,
     "status": "ok",
     "timestamp": 1624589418673,
     "user": {
      "displayName": "Riemer Dijkstra",
      "photoUrl": "",
      "userId": "01054650060903474658"
     },
     "user_tz": -120
    },
    "id": "Um9-BodkH2TM",
    "outputId": "73257cb1-1ad5-40e3-a161-76005de9e8b2"
   },
   "outputs": [],
   "source": [
    "corpus = make_file(wiki_set[0:10], multi=True, pos=False)\n",
    "  \n",
    "rank_corp, freq_corp = subsampling(corpus, k=100, m=10)\n",
    "ranks_freqs_df = ranks_freqs(rank_corp, freq_corp, text=None, norm=None)\n",
    "ranks_freqs_df, params = zipfs_law(ranks_freqs_df, print_stats=False)\n",
    "\n",
    "def probability(txt, params):\n",
    "  corpus = make_file(txt, multi=False, pos=False)\n",
    "  rank, freq = subsampling(corpus, k=10, m=10)\n",
    "  mandel = Mandelbrot(freq, rank)\n",
    "  mandelbrot_fit = mandel.fit(start_params=np.asarray([1.0, 1.0]),\n",
    "                                method=\"powell\", full_output=True)\n",
    "  mandel.register_fit(mandelbrot_fit)\n",
    "  return mandel.loglike(params, frequencies=freq, ranks=rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KowVZDKnDAfd"
   },
   "outputs": [],
   "source": [
    "def rejection(txt):\n",
    "\n",
    "  i = 0\n",
    "  sections = txt.split('\\n\\n')\n",
    "  new_txt = []\n",
    "\n",
    "  for txt in wiki_set:\n",
    "    seeds = np.linspace(0, , num=101)\n",
    "    while i <= 20:\n",
    "      sec_len = len(section.split())\n",
    "      if sec_len > 10:\n",
    "        curr_snippet = generate_section(section, min_tokens=sec_len, p=0.95, n_gram=3, seed=seed)\n",
    "\n",
    "        if prob(curr_snippet, params) >= treshold:\n",
    "          new_tokens.extend(curr_snippet[:sec_len] + [\"\\n\\n\"])\n",
    "          break\n",
    "\n",
    "        else:\n",
    "          seed_list.append(seed)\n",
    "          seed += 1\n",
    "          i += 1\n",
    "\n",
    "  return \" \".join(new_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_section(section, min_tokens, k, p, t, rep_pen, n_gram, seed):\n",
    "    \n",
    "    prompt = make_prompt(section, begin=True)\n",
    "    prompt_len = len(prompt.split())\n",
    "        \n",
    "    in_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
    "    in_ids = in_ids.to(\"cuda\")\n",
    "    \n",
    "    curr_id_len = len(in_ids[0])\n",
    "    max_len = min_len = curr_id_len+128\n",
    "\n",
    "    out = []\n",
    "    \n",
    "    while len(out) <= min_tokens:\n",
    "        \n",
    "        torch.manual_seed(seed)\n",
    "            \n",
    "        out_ids = model.generate(\n",
    "            in_ids,\n",
    "            do_sample=True,\n",
    "            max_length=max_len,\n",
    "            min_length=min_len,\n",
    "            top_k=k,\n",
    "            top_p=p,\n",
    "            temperature=t,\n",
    "            repetition_penalty=rep_pen,\n",
    "            no_repeat_ngram_size=n_gram\n",
    "        )\n",
    "        \n",
    "        output = tokenizer.decode(out_ids[0], skip_special_tokens=True).split()      \n",
    "        output_no_prompt = output[prompt_len:]\n",
    "        out.extend(output_no_prompt)\n",
    "        \n",
    "        output_full = \" \".join(output)\n",
    "        prompt = make_prompt(output_full, begin=False)\n",
    "        prompt_len = len(prompt.split())\n",
    "                \n",
    "        in_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
    "        in_ids = in_ids.to(\"cuda\")\n",
    "        \n",
    "        # Error control\n",
    "        if len(in_ids[0]) == curr_id_len+128:\n",
    "            \n",
    "            print('in_id error')\n",
    "            \n",
    "            out_sents = nltk.tokenize.sent_tokenize(\" \".join(out))\n",
    "            if len(out_sents) > 1:\n",
    "                new_sents = \" \".join(out_sents[:-2])\n",
    "            else:\n",
    "                new_sents = \" \".join(out_sents)\n",
    "\n",
    "            out = new_sents.split()\n",
    "            \n",
    "            prompt = make_prompt(new_sents, begin=False)\n",
    "            prompt_len = len(prompt.split())\n",
    "            \n",
    "            in_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
    "            in_ids = in_ids.to(\"cuda\")\n",
    "            \n",
    "        curr_id_len = len(in_ids[0])\n",
    "        max_len = min_len = curr_id_len+128\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(txt, k, p, t, rep_pen, n_gram, seed):\n",
    "    \n",
    "    new_tokens = []\n",
    "\n",
    "    sections = txt.split('\\n\\n')\n",
    "    for section in sections:\n",
    "        sec_len = len(section.split())\n",
    "        if sec_len > 10:\n",
    "            \n",
    "            curr_tokens = generate_section(\n",
    "                section, \n",
    "                min_tokens=sec_len, \n",
    "                k=k, \n",
    "                p=p, \n",
    "                t=t, \n",
    "                rep_pen=rep_pen, \n",
    "                n_gram=n_gram,\n",
    "                seed=seed\n",
    "            )\n",
    "            \n",
    "            new_tokens.extend(curr_tokens[:sec_len] + [\"\\n\\n\"])\n",
    "\n",
    "    new_txt = \" \".join(new_tokens)\n",
    "    return new_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "corpus = []\n",
    "\n",
    "def rejection(txt):\n",
    "  seeds = np.linspace(0, 20, num=21)\n",
    "  for seed in seeds:\n",
    "    curr_txt = generate(txt, k=None, p=0.95, t=1, rep_pen=1.0, n_gram=3, seed=seed)\n",
    "    if test(curr_txt, 1):\n",
    "      return curr_txt\n",
    "  return False\n",
    "\n",
    "def test_batch(texts):\n",
    "  corpus = make_file(texts, multi=True, pos=False)\n",
    "  return test(corpus, 10)\n",
    "\n",
    "texts = []\n",
    "for txt in wiki_set:\n",
    "  sample = rejection(txt)\n",
    "  if sample is not False:\n",
    "    texts.append(sample)\n",
    "  if len(texts) == 10:\n",
    "    if test_batch(texts):\n",
    "      print(texts)\n",
    "      break\n",
    "    else:\n",
    "      texts = []"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO2ZO5oy1u61anQnoluvgQZ",
   "collapsed_sections": [],
   "name": "Rejection_sampling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0048304c20d64cbe8d4c6a4713dded11": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "08b15cd436644910980e60f9d876b934": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "17a3b5fa575f438b9575182f0479fe4d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7f5df7cb170d49bb8e839b07f5ccf574",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_62aed2da6d9144aba3dc6ff0865a9b4f",
      "value": 456318
     }
    },
    "21264b9ba0b84c11ab38ba2850ea56d1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "257e52d3ac734ad38c131618b2eb701f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8510afa35f204020832c07a37356e034",
      "placeholder": "​",
      "style": "IPY_MODEL_a58e87e0e3cb4527bdd2c1c0419b6d69",
      "value": " 548M/548M [00:13&lt;00:00, 39.8MB/s]"
     }
    },
    "2e8829f9d9b64bbbb5f87c646eea41d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3666e841186942f786735bb4855c62ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "39650bc1c98a4a9da39fa13cfea6714d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "3a76b63949014a4496553ecaf14ef359": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "420e2c3ef8cc456dab537fb2827cffe1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "44ff5e992b924286b45dd03fbd44747c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c2028efcaac14b5ab95ee2e2021ded71",
      "max": 548118077,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_39650bc1c98a4a9da39fa13cfea6714d",
      "value": 548118077
     }
    },
    "4b71f1fec57345eabe06d30474e4a92e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "62399ecdd8ef45ba9e00a8c21066b366": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "62aed2da6d9144aba3dc6ff0865a9b4f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "6d9760a4922d4406ba5175d2e135c6e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "72332c302797499284bf5a262c7a11a9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7442df3d662d4fa8bf66fe80e4807502": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b9c06a0281274909a06a77302ea43b96",
       "IPY_MODEL_9518fb90c2674070b00b5b85f1945cb4"
      ],
      "layout": "IPY_MODEL_420e2c3ef8cc456dab537fb2827cffe1"
     }
    },
    "7f5df7cb170d49bb8e839b07f5ccf574": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8510afa35f204020832c07a37356e034": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "894105888abe40408e128ffe231edd97": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8ce96608d3fe4dcca5f47ee9da80cae5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e7e64c3e2c974e5185a2c97e49d4391c",
       "IPY_MODEL_ddb279d017934b5d899beb6ba9b19b35"
      ],
      "layout": "IPY_MODEL_c910715cd8854f81999fbba19a474a00"
     }
    },
    "9518fb90c2674070b00b5b85f1945cb4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_21264b9ba0b84c11ab38ba2850ea56d1",
      "placeholder": "​",
      "style": "IPY_MODEL_08b15cd436644910980e60f9d876b934",
      "value": " 1.36M/1.36M [00:00&lt;00:00, 1.54MB/s]"
     }
    },
    "95464dd3ba284517a22da28b78fea530": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a059d4ee61964a3d8af5512a0c1bcf5e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c153f5a9adbb4b35918817a42b791025",
       "IPY_MODEL_abaeb1c0a87541fab1ff33428e4d4631"
      ],
      "layout": "IPY_MODEL_72332c302797499284bf5a262c7a11a9"
     }
    },
    "a58e87e0e3cb4527bdd2c1c0419b6d69": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "abaeb1c0a87541fab1ff33428e4d4631": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_95464dd3ba284517a22da28b78fea530",
      "placeholder": "​",
      "style": "IPY_MODEL_2e8829f9d9b64bbbb5f87c646eea41d0",
      "value": " 665/665 [00:00&lt;00:00, 2.34kB/s]"
     }
    },
    "b9c06a0281274909a06a77302ea43b96": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3a76b63949014a4496553ecaf14ef359",
      "max": 1355256,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6d9760a4922d4406ba5175d2e135c6e4",
      "value": 1355256
     }
    },
    "c153f5a9adbb4b35918817a42b791025": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e4d8750fa76148088ccf0b6476a5ecef",
      "max": 665,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3666e841186942f786735bb4855c62ea",
      "value": 665
     }
    },
    "c2028efcaac14b5ab95ee2e2021ded71": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c910715cd8854f81999fbba19a474a00": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ce65de69034346b088ef352c887df60e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d71759655da840b592ea3f1584b97dc8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ddb279d017934b5d899beb6ba9b19b35": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4b71f1fec57345eabe06d30474e4a92e",
      "placeholder": "​",
      "style": "IPY_MODEL_ce65de69034346b088ef352c887df60e",
      "value": " 1.04M/1.04M [00:07&lt;00:00, 133kB/s]"
     }
    },
    "de29825227524215b9f74d29a293d05c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_894105888abe40408e128ffe231edd97",
      "placeholder": "​",
      "style": "IPY_MODEL_0048304c20d64cbe8d4c6a4713dded11",
      "value": " 456k/456k [00:04&lt;00:00, 101kB/s]"
     }
    },
    "e0dc6290c0b145cf8d7a3a98e7a8b04c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e1009d8b9f694b0bba841632ecceb970": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e1be793186634798b916839edbe61e6f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_17a3b5fa575f438b9575182f0479fe4d",
       "IPY_MODEL_de29825227524215b9f74d29a293d05c"
      ],
      "layout": "IPY_MODEL_d71759655da840b592ea3f1584b97dc8"
     }
    },
    "e4d8750fa76148088ccf0b6476a5ecef": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e7e64c3e2c974e5185a2c97e49d4391c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e1009d8b9f694b0bba841632ecceb970",
      "max": 1042301,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_62399ecdd8ef45ba9e00a8c21066b366",
      "value": 1042301
     }
    },
    "f11696934ca84ae1b861d75d317a90f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_44ff5e992b924286b45dd03fbd44747c",
       "IPY_MODEL_257e52d3ac734ad38c131618b2eb701f"
      ],
      "layout": "IPY_MODEL_e0dc6290c0b145cf8d7a3a98e7a8b04c"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
